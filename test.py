from transformers import pipeline

summarizer = pipeline("summarization", model="IlyaGusev/rut5-base-summarization")

text = "–ú–æ–±–∏–ª—å–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ —Å—Ç–∞–ª–æ –Ω–µ—É–¥–æ–±–Ω—ã–º –ø–æ—Å–ª–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è. –ß–∞—Å—Ç–æ –ø—Ä–∏—Ö–æ–¥–∏—Ç—Å—è –∑–∞–Ω–æ–≤–æ –≤—Ö–æ–¥–∏—Ç—å, –∏ –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ —Å—Ç–∞–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã."

summary = summarizer(text, max_length=60, min_length=20, do_sample=False)[0]["summary_text"]

print("–°–≤–æ–¥–∫–∞:", summary)


# import json
# from abstractive import abstractive_summary

# reviews = [
#     "–°–∞–º—ã–π —Ö—É–¥—à–∏–π –±–∞–Ω–∫, –Ω–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É—é. –î–µ–Ω—å–≥–∏ –ø—Ä–æ–ø–∞–¥–∞—é—Ç, –ø–æ—Å—Ç–æ—è–Ω–Ω–æ –ø—Ä–æ–≥—Ä–∞–º–º–∞ –∑–∞–≤–∏—Å–∞–µ—Ç.",
#     "–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ —Ö–æ—Ä–æ—à–µ–µ, –Ω–æ –≤—Å–µ–≥–¥–∞ —Ç—É–ø–∏—Ç –∏ –∏–Ω–æ–≥–¥–∞ —É –º–µ–Ω—è –ø—Ä–æ–ø–∞–¥–∞—é—Ç –¥–µ–Ω—å–≥–∏. –Ø –ø–∏—Å–∞–ª–∞, –Ω–æ –º–Ω–µ –Ω–µ –ø–æ–º–æ–≥–ª–∏.",
#     "–í—Å—ë –æ—Ç–ª–∏—á–Ω–æ! –ü–æ–ª—å–∑—É—é—Å—å –¥–∞–≤–Ω–æ, –Ω–∞—Ä–µ–∫–∞–Ω–∏–π –Ω–µ—Ç.",
#     "–°–æ–≤—Å–µ–º –ø–µ—Ä–µ—Å—Ç–∞–ª —Ä–∞–±–æ—Ç–∞—Ç—å. –í–æ–π—Ç–∏ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ.",
#     "–û—á–µ–Ω—å –Ω–µ—É–¥–æ–±–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –∏ –º–µ–¥–ª–µ–Ω–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞."
# ]

# print("üîç –ê–±—Å—Ç—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ —Å–≤–æ–¥–∫–∏ –æ—Ç–∑—ã–≤–æ–≤:\n")

# for i, review in enumerate(reviews, 1):
#     print(f"üìù –û—Ç–∑—ã–≤ #{i}: {review}")
#     summary = abstractive_summary(review)
#     print(f"üî∏ –ê–±—Å—Ç—Ä–∞–∫—Ç–∏–≤–Ω–∞—è —Å–≤–æ–¥–∫–∞: {summary}")
#     print("-" * 60)



# —ç–∫—Å—Ç—Ä–∞–∫—Ç
# from razdel import sentenize
# from sentence_transformers import SentenceTransformer
# from sklearn.metrics.pairwise import cosine_similarity
# import numpy as np

# model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

# def extractive_summary(text, top_n=1):
#     sentences = [s.text.strip() for s in sentenize(text) if s.text.strip()]

#     if len(sentences) <= top_n:
#         return " ".join(sentences)

#     embeddings = model.encode(sentences)
#     mean_embedding = np.mean(embeddings, axis=0)
#     scores = cosine_similarity([mean_embedding], embeddings)[0]

#     top_indices = np.argsort(scores)[-top_n:]
#     top_indices.sort()

#     return " ".join([sentences[i] for i in top_indices])




